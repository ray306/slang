</head>
 <!-- FlatFy Theme - Andrea Galanti /-->
<!doctype html>
<!--[if lt IE 7]> <html class="no-js ie6 oldie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js ie7 oldie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js ie8 oldie" lang="en"> <![endif]-->
<!--[if IE 9]>    <html class="no-js ie9" lang="en"> <![endif]-->
<!--[if gt IE 9]><!--> <html> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="description" content="NPL Group – Researching in Neuro&Psycho&Lanuage ">
    <meta name="author" content="">

    <title>Xing Tian - SLANG (Speech, language, and Neuroscience Group)</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
 
    <!-- Custom Google Web Font -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="css/fonts.css" rel="stylesheet">
<!--     <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Arvo:400,700' rel='stylesheet' type='text/css'> -->
    
    <!-- Custom CSS-->
    <link href="css/general.css" rel="stylesheet">
    
     <!-- Owl-Carousel -->
    <link href="css/custom.css" rel="stylesheet">
    <link href="css/owl.carousel.css" rel="stylesheet">
    <link href="css/owl.theme.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link href="css/animate.css" rel="stylesheet">

    <!-- markdown -->
    <link href="css/typora_markdown.css" rel="stylesheet">
    
    <!-- Magnific Popup core CSS file -->
    <link rel="stylesheet" href="css/magnific-popup.css"> 
    
    <script src="js/modernizr-2.8.3.min.js"></script>  <!-- Modernizr /-->
    <!--[if IE 9]>
        <script src="js/PIE_IE9.js"></script>
    <![endif]-->
    <!--[if lt IE 9]>
        <script src="js/PIE_IE678.js"></script>
    <![endif]-->

    <!--[if lt IE 9]>
        <script src="js/html5shiv.js"></script>
    <![endif]-->

</head>

<body id="home">
    <!-- Preloader -->
    <div id="preloader">
        <div id="status"></div>
    </div>
    
    <!-- NavBar-->
    <nav class="navbar-default" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#home">Xing Tian (Speech, Language and Neuroscience Group)</a>
                <img class="main_logo lazy" data-original="img/logo.png">
            </div>

            <div class="collapse navbar-collapse navbar-right navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <li class="menuItem"><a href="index.html">SLANG</a></li>
                    <li class="menuItem"><a href="#top">Top</a></li>
                    <li class="menuItem"><a href="#Research">Research</a></li>
                    <li class="menuItem"><a href="#People">People</a></li>
                    <li class="menuItem"><a href="#Publications">Publications</a></li>
                    <li class="menuItem"><a href="#Teaching">Teaching</a></li>
                    <li class="menuItem"><a href="#Open Positions">Open Positions</a></li>
                    <li class="menuItem"><a href="#Resources">Resources</a></li>
                    <li class="menuItem"><a id="#Contact">Contact</a></li>
                </ul>
            </div>
           
        </div>
    </nav>

<div id="top" class="content-section-a typora-export">
  <div  id='write'  class = 'is-node'>
    <div class="row">
        <h2>Xing Tian</h2><h5></a>Assistant Professor of Neural and Cognitive Sciences at NYU Shanghai</h5>
        <div class="col-md-3">
            <img data-original="img/member/Tian Xing.jpg" alt="" class="img-responsive img-circle lazy"/>
        </div>
        <div class="col-md-offset-4 overview">
            <span>Speech is the most fundamental and natural way that enables us to communicate every day. We need to constantly receive and produce sounds to effectively exchange information, which demands an effective interface between perception and production. 
            Using electrophysiological (MEG/EEG/ECoG) and neuroimaging (fMRI) techniques with behavioral and computational approaches, we aim to investigate the function of motor sensory interaction, which is at the core of the speech perception-production control loop, as well as its relation to language, learning, memory, mental imagery, and other higher order cognitive functions. 
            More generally, I use speech and language as a model to investigate neural computations underlying human cognition. Please refer to Research for more scientific details.</span>
        </div>
    </div>
  </div>
</div> 

<div id="Research" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
      <h2><a name='header-c3959' class='md-header-anchor '></a>Research</h2><p>Broadly speaking, my research is in the field of cognitive neuroscience, in which the major task is to investigate the neural bases of (human) cognition. It includes at least two major directions ofresearch – neural representation and neural computation. Neural representation is how information is represented in our brain; neural computation is how the neural representation is formed and manipulated. I believe there are generic kinds of neural computation, called <strong>canonical neural computation</strong>, which can be applied to information processes indifferent modalities and cognitive domains. <strong>For my specific research interest I use speech and language as a model to investigate canonical neural computation underlying human cognition.</strong> Two kinds of canonical neural computation is of particular interest: </p><ul><li><p><strong>Transformation</strong>:</p><p>Variables or representation change over time and/or across brain functional regions. The focus is motor-to-sensory transformation and its functionality on(speech and language) behavior, which includes its putative computational function in the following research topics:</p><ul><li><strong>Speech production and control:</strong> The high computational demand of speech (e.g., producing 4-8 syllable per second) needs an efficient way to provide control. I have proposed a motor-to-sensory transformation in a sequential manner for speech control (fig. 1), and a series of studies have been carried out to test the proposed model. Many aspects and questions still need to be addressed. For example, whatare the computational roles of motor-to-sensory transformation in speech control? And what are the neural mechanisms and implementation? </li><li><strong>Perception</strong>: One theory that links motor and perception is the motor theory of speech perception and language comprehension. Numerous studies have observed activity in motorregions while listening to speech or reading words (verbs) and sentences. Butthe function of motor activation during perception is still debated. Canmotor-to-sensory transformation offer a mechanistic account for these data and explain why motor regions are engaged during perception? Ultimately, can motor-to-sensory transformation address the invariance problem in speechperception? </li><li><strong>Learning</strong>:  Second language (L2) and bilingualism are our focus. Learning, especially for speech essentially creates a perception-action mapping – which requires the reproduction of sound patterns with certain meanings. So, do L2 learningrecruit motor-to-sensory transformation? How do the representational changes between languages engage the motor-to-sensory transformation in bilinguals? </li><li><strong>Memory, mental imagery,and other higher order cognitive function</strong>: Bothmotor-to-sensory transformation and memory retrieval can induce internal neuralrepresentation without external stimulation (fig. 2). How do they differ? Whatare their functional specificity, especially in speech and language? Moreover, how do the internally induced neural representation link to our subjective feeling of imagination?</li><li><strong>For special populations</strong>: Can motor-to-sensory transformation be the underlying mechanism for the positive symptoms in special populations, such as those with speech and language deficits (e.g., stuttering, dyslexia), and those with mental and neural disorders (e.g., auditory hallucination in schizophrenia, also see point 6 below)? </li><li><strong>Agency and self-monitoring</strong>: How can we have body ownership (knowing our body is ours and under our control, incontrast to cases like rubber hand illusion and phantom limb sensation), and identify incoming stimulation as generated by ourselves (e.g. speech feedback is produced by me, in contrast to cases like auditory hallucination)? Can motor-sensory transformation in combination with perception provide us agency andself-monitoring function? (See section II. Integration for more details.) </li></ul></li><li><p><strong>Integration</strong>: </p><p>   Combining information across time, locations, or modalities, usually creates new representations. My research focus in this direction is on temporal integration(mostly with my collaborators) and multi-modal integration:</p><ul><li><p><strong>Temporal integration </strong>(collaborating with Nai Ding, Xiangbin Teng, and David Poeppel):
      Similar kinds of information are summarize over time (e.g., sounds, written words, and their following linguistic processes). One theory proposed that neural oscillations may serve as an integrative function during speech perception (may come with a figure like Jinbiao’s reading experiment – Yi3 Yi4 Dai4 Lao2, in Nai’s formatwith additional acoustic waveforms). How do the neural oscillations mediate the integrative process, as well as speech perception and language comprehension? (How do the proposed neural oscillations relate to memory 2013 curr bio and 2015 sci report?) [integration and process of before and after] e.g.(retrieval) integration and comparison, as well as later evaluation process(N400) ?</p></li><li><p><strong>Multi-modal integration</strong>: Informationfrom different sources are combined together. The common kind of multi-modalintegration is multisensory integration (e.g., visual-auditory integration – looking at a person’s face while listening to speech). I am particularly interested in how motor and other cognitive functions integrate, and thefunction of such integration. This multi-modal integration differs from thecommon multisensory integration in that it does not require information coming from external sources. Instead, the information can be induced internally, suchas via motor-to-sensory transformation. For example, </p><p>   ​    1) how does the motor-to-sensory transformation integrate with external feedback for speech control? What would the computation be when they are (temporally, spectrally, or spatially) inconsistent?</p><p>   ​    2) How are the senses of agency and function of self-monitoring obtained by integrating motor-to-sensory transformation andsensory feedback? </p><p>   ​    3) Can motor-to-sensory transformation integrate with other information to create new (episodic and semantic) memory? </p></li></ul></li></ul><p>I am also interested in cross-disciplinary research, such as between neuroscience and computer science. By collaborating with faculty in computer science (ZhengZhang and Xipeng Qiu), we are aiming to build a bridge between artificial intelligence (AI) and human intelligence in the areas of speech and language. For example, we investigate the commonality between natural language processing and neural bases of language processing, especially in the aspect of semantics. Moreover, we would like to use recurrent neural network models to test neuroscience theories and models, such as lateralization and motor-to-sensory transformation.The purpose of this endeavor is to advance both fields – borrow methods andmodels from computer science to understand our brain better, while lending neuroscience findings, and models to make AI smarter and more human-like. </p>
  </div>
</div>

<div id="People" class="content-section-a typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4011' class='md-header-anchor '></a>People</h2><h4><a name='header-c4012' class='md-header-anchor '></a>Principal Investigator</h4><ul><li>Xing Tian (<a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a>)
    Assistant Professor of Neural and CognitiveSciences</li></ul><h4><a name='header-c4018' class='md-header-anchor '></a>Research Associates</h4><ul><li>Fan Bai</li><li>Jinbiao Yang</li></ul><h4><a name='header-c4026' class='md-header-anchor '></a>Postdoctoral fellows</h4><ul><li>Xiaoluan Liu</li></ul><h4><a name='header-c4031' class='md-header-anchor '></a>Graduate students</h4><ul><li>Lingting Wang (ECNU-NYU)</li></ul><h4><a name='header-c4036' class='md-header-anchor '></a>Undergraduate Research Assistants</h4><ul><li>Defne Inhan (NYUSH)</li><li>Tehreem Nihar (NYUSH)</li><li>Tianyi Bill Zheng (NYUSH, co-advisingwith Zheng Zhang)</li><li>Ning Mei (NYU)</li></ul><h4><a name='header-c4050' class='md-header-anchor '></a>Alumni</h4><h5><a name='header-c4051' class='md-header-anchor '></a>Research Assistants/Interns</h5><ul><li>Anna Zhen (U of Chicago)</li><li>Danfeng Wu (MIT)</li><li>Stella Yuan (Carnegie Mellon University) </li></ul><h4><a name='header-c4062' class='md-header-anchor '></a>Collaborators</h4><ul><li>Qing Cai (ECNU) </li><li>Zheng Zhang (NYU Shanghai) </li><li>Diogo Almeida (NYU Abu Dhabi) </li><li>Nai Ding (Zhe Jiang University) </li><li>Huan Luo (Peking University) </li><li>Lucia Melloni (NYU and Max-Planck) </li><li>Xiangbin Teng (NYU and Max-Planck) </li><li>QianWang (San Bo Hospital)</li></ul>
  </div>
</div>

<div id="Publications" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4091' class='md-header-anchor '></a>Publications</h2><blockquote><p>Teng, X., Tian, X., &amp; Poeppel, D.(2016). Testing multi-scale processing in the auditory system. <em>Scientific Reports</em>, 6, 34390. doi:10.1038/srep34390</p></blockquote><blockquote><p>Ding, N., Melloni, L., Tian, X., &amp;Poeppel, D. (2016). Rule-based and word-level statistics-based processing of language: insights from neuroscience. <em>Language,Cognition and Neuroscience</em>, 1-6. doi: 10.1080/23273798.2016.1215477</p></blockquote><blockquote><p>Tian, X., Zarate, J.M., Poeppel, D.(2016). Mental imagery of speech implicates two mechanisms of perceptual reactivation. <em>Cortex</em>. 77, 1-12. doi: 10.1016/j.cortex.2016.01.002</p></blockquote><blockquote><p>Ding, N., Melloni, L., Zhang, H., Tian,X., Poeppel, D. (2016). Cortical tracking of hierarchical linguistic structure in connected speech. <em>Nature Neuroscience</em>.19(1), 158-164.</p></blockquote><blockquote><p>Zarate, J.M.<em>, Tian, X.</em>, Woods, K.J.P.,&amp; Poeppel, D. (2015). Multiple levels of linguistic and paralinguistic features contribute to voice recognition. <em>Scientific Reports</em>. 5: 11475. doi: 10.1038/srep11475 (*equal contribution)</p></blockquote><blockquote><p>Tian, X., &amp; Poeppel, D. (2015). Dynamics of self-monitoring and error detection in speech production: evidence from mental imagery MEG.  <em>Journal of Cognitive Neuroscience.</em> 27(2), 352-364.</p></blockquote><blockquote><p>Tian, X., &amp; Poeppel, D. (2013). The effect of imagination on stimulation: the functional specificity of efference copies in speech processing.  <em>Journal of Cognitive Neuroscience.</em> 25(7), 1020-1036.</p></blockquote><blockquote><p>Luo<em>, H., Tian</em>, X., Song, K., Zhou, K., &amp; Poeppel, D. (2013). Neural response phase tracks how listeners learn new acoustic representations. <em>Current Biology</em>. 23(11), 968–974.(*equal contribution)</p></blockquote><blockquote><p>Tian, X., &amp; Huber, D.E. (2013). Playing ‘Duck Duck Goose’ with neurons: Change detection through connectivity reduction. <em>Psychological Science</em>.24(6), 819–827.</p></blockquote><blockquote><p>Tian, X., &amp; Poeppel, D. (2012). Mental imagery of speech: linking motor and sensory systems through internals imulation. <em>Front. Hum. Neurosci.</em> 6:314. doi: 10.3389/fnhum.2012.00314</p></blockquote><blockquote><p>Wu, J., Duan, H., Tian, X., Wang, P.,&amp; Zhang, K. (2012). The effects of visual imagery on face identification: an ERP study. <em>Front. Hum. Neurosci.</em> 6:305. doi: 10.3389/fnhum.2012.00305</p></blockquote><blockquote><p>Davelaar, E.J., Tian, X., Weidemann, C.T., &amp; Huber, D.E. (2011). A habituation account of change detection insame/different judgments. <em>Cognitive,Affective and Behavioral Neuroscience</em>, <em>11</em>,608-626.</p></blockquote><blockquote><p>Tian, X., Poeppel, D., &amp; Huber, D.E. (2011). TopoToolbox: Using sensor topography to calculate psychologically meaningful measures from event-related EEG/MEG. <em>Computational Intelligence and Neuroscience</em>. <em>2011,</em>doi:10.1155/2011/674605</p></blockquote><blockquote><p>Tian, X., &amp; Poeppel, D. (2010). Mental imagery of speech andmovement implicates the dynamics of internal forward models. <em>Front. Psychology,</em> 1:166. doi: 10.3389/fpsyg.2010.00166</p></blockquote><blockquote><p>Tian, X., &amp; Huber, D.E. (2010). Testing an associative account of semantic satiation. <em>Cognitive Psychology,60</em>, 267-290.</p></blockquote><blockquote><p>Tian, X., &amp; Huber,D.E. (2008). Measures of spatial similarity and response magnitude in MEG andscalp EEG. <em>Brain Topography</em>, <em>20</em>,131-141.</p></blockquote><blockquote><p>Huber, D. E., Tian, X., Curran, T., O’Reilly, C, &amp; Woroch, B. (2008). The dynamics of integration and separation: ERP, MEG, and neural network studies of immediate repetition effects. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>34</em>,1389-1416.</p></blockquote>
  </div>
</div>

<div id="Teaching" class="content-section-a typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4146' class='md-header-anchor '></a>Teaching</h2><h3><a name='header-c4147' class='md-header-anchor '></a>Course</h3><ul><li>Undergraduate, Behavioral and Integrative Neuroscience, NYU Shanghai 2016</li><li>Undergraduate, Neural Bases of Speech and Language, NYU Shanghai 2015, 2016</li></ul><h3><a name='header-c4153' class='md-header-anchor '></a>Guest Lecturer</h3><ul><li>“Speech perception and production”, Cognitive Neuroscience, Institute of Cognitive Neuroscience, ECNU 2016</li><li>“Neural computation in speech”, Frontiers in Cognitive Neuroscience research, Institute of Cognitive Neuroscience, ECNU 2016</li><li>“Language”, Behavioral and Integrative Neuroscience (by Clayton Curtis), Neuroscience program, NYU Shanghai 2015</li><li>“MEG fundamentals”, Laboratory in Cognitive Neuroscience (by David Poeppel), Department of Psychology, New York University 2012</li><li>“Testing psychological theories using electrophysiological methods”, Cognitive Neuroscience (by Zoran Josipovic), Department of Psychology, New York University 2012</li></ul>
  </div>
</div>

<div id="Open Positions" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4175' class='md-header-anchor '></a>Open Positions</h2><ul><li><h3><a name='header-c4178' class='md-header-anchor '></a>Postdoctoral Fellow</h3><p>Multiple postdoctoral positions are available to investigate the neural mechanisms of speech production and perception, with a focus of sensorimotor integration and its contribution to representation and computation in speech, language, memory and other higher order cognition. For information about applying, please click here (<a href='http://shanghai.nyu.edu/about/work/fellowships' target='_blank' >http://shanghai.nyu.edu/about/work/fellowships</a>). Job inquires can be sent to <a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a></p></li><li><h3><a name='header-c4182' class='md-header-anchor '></a>Prospective Graduate Students</h3><p>Students interested in cognitive neuroscience have two ways to join our lab, either via NYU Neuroscience Doctoral Program Shanghai Track or ECNU Brain and Cognitive Science Graduate Program Track.  Detailed information can be found here (<a href='http://neuro.shanghai.nyu.edu/graduate' target='_blank' >http://neuro.shanghai.nyu.edu/graduate</a>). Prospective students are encouraged to contact me via <a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a></p></li><li><h3><a name='header-c4186' class='md-header-anchor '></a>Undergraduate Research Opportunities</h3><p>Our lab opens to motivated undergraduate students who are interested in conducting independent research on human cognitive functions, including speech, language, memory and other higher order cognitive function. Please send your CV, description of your research interests, and a copy of unofficial transcripts to <a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a>.</p></li></ul>
  </div>
</div>

<div id="Resources" class="content-section-a typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4192' class='md-header-anchor '></a>Resources</h2><ul><li><h3><a name='header-c4195' class='md-header-anchor '></a>Topo Toolbox</h3><p><em>Click here to download the <a href="files/TopoToolbox.zip">ZIP</a> file that contains the main functions, a detailed tutorial, manual and sample data. The tutorial and manual can also be download separately: <a href="files/TopoToolbox tutorial.pdf">tutorial</a>, <a href="files/TopoToolbox manual.pdf">manual</a>. </em></p></li></ul><p>TopoToolbox is an open-source software for topographic analysis on the event-related electrophysiological (EEG/MEG) data based on the method proposed by Tian and Huber (2008; 2011). TopoToolbox provides a tool for researchers to directly derive robust measures of response pattern (topographic) similarity and psychological meaningful response magnitude using electromagnetic signals in sensor space. These measures are useful for testing psychological theories without anatomical descriptions.
    Three functions are provided in this toolbox:</p><ol start='' ><li><p>Angle test: testing topographic similarity between experimental conditions</p></li><li><p>Projection test: normalizing individual difference against a template to measure response magnitude</p></li><li><p>Angle dynamics test: assessing pattern similarity over time. 
    This toolbox is developed by Dr. Xing Tian, Dr. David Poeppel and Dr. David E. Huber. It requires MATLAB (The Mathworks, Inc.) environments and supports various of standard data format imported from EEGLAB as well as user defined dataset. Please cite the following references if you use the TopoToolbox for publications or public releases:</p><blockquote><p>Tian, X., &amp; Huber, D. (2008). Measures of spatial similarity and response magnitude in MEG and scalp EEG. <em>Brain Topography, 20</em>(3), 131-141.</p></blockquote><blockquote><p>Tian, X., Poeppel, D., &amp; Huber, D.E. (2011). TopoToolbox: Using sensor topography to calculate psychologically meaningful measures from event-related EEG/MEG. <em>Computational Intelligence and Neuroscience</em>, 2011. doi:10.1155/2011/674605</p></blockquote></li></ol><p>Should you have any questions or comments regarding this toolbox, please contact me at <a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a></p>
  </div>
</div>

<div id="Contact" class="content-section-b typora-export"  style="border-top: 0">
  <div  id='write'  class = 'is-node'>
    <h2><a name='header-c4222' class='md-header-anchor '></a>Contact</h2><p>Prospective students, postdoctoral researchers and collaborators are welcomed to contact us directly.</p><p>Xing Tian (田兴)
    E-mail: <a href='mailto://xing.tian@nyu.edu' target='_blank' >xing.tian@nyu.edu</a></p><ul><li>Pudong Campus:
    1555 Century Avenue, Room 1138│ 世纪大道1555号1138室
    Shanghai, China 200122
    Office: +86 (21) 20595201 </li><li>Puxi ECNU Campus:
    3663 Zhongshan Road North, Geographybuilding, Room 140 | 华东师范大学中山北路3663号地理楼140室
    Shanghai, China 200062
    Office: +86(21)20595996</li></ul>
  </div>
</div>


    <!-- Contact -->
    <footer>
        <div class="container">
            <h5>Copyright (c) 2016 Speech, language, and Neuroscience Group. Built by Jinbiao(Ray) Yang using the theme based on <a href="https://github.com/andreagalanti/Flatfy-Free-Flat-and-Responsive-HTML5-Template">Flatfy</a>.</h5>
                <li></li>
            
        </div>
    </footer>
    <!-- keep the navbar fixed-->
    <div class="morph-button morph-button-inflow morph-button-inflow-1">
        <button type="button "></button>
    </div>
    <!-- JavaScript -->
    <script src="js/jquery.min.js"></script>
    <script src="js/jquery.lazyload.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/owl.carousel.js"></script>
    <script src="js/script.js"></script>
    <!-- StikyMenu -->
    <script src="js/stickUp.min.js"></script>
    <script type="text/javascript">
      jQuery(function($) {
        $(document).ready( function() {
          $('.navbar-default').stickUp();
          $(".tooltip-options").tooltip({html : true });
        });
      });

      $(function() {
        $("img.lazy").lazyload();
    });

      $('#internal').click(function(){
            var internal = window.prompt("Please enter the password:", "");
            if(internal.length>0){window.location.href = internal+'.html';} 
        });
    </script>
    <!-- Smoothscroll -->
    <script type="text/javascript" src="js/jquery.corner.js"></script> 
    <script src="js/wow.min.js"></script>
    <script>
     new WOW().init();
    </script>
    <script src="js/classie.js"></script>
    <script src="js/uiMorphingButton_inflow.js"></script>
    <!-- Magnific Popup core JS file -->
    <script src="js/jquery.magnific-popup.js"></script> 
</body>

</html>

</html>